<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>GPU Acceleration · SHTnsKit.jl</title><meta name="title" content="GPU Acceleration · SHTnsKit.jl"/><meta property="og:title" content="GPU Acceleration · SHTnsKit.jl"/><meta property="twitter:title" content="GPU Acceleration · SHTnsKit.jl"/><meta name="description" content="Documentation for SHTnsKit.jl."/><meta property="og:description" content="Documentation for SHTnsKit.jl."/><meta property="twitter:description" content="Documentation for SHTnsKit.jl."/><meta property="og:url" content="https://subhk.github.io/SHTnsKit.jl/stable/gpu/"/><meta property="twitter:url" content="https://subhk.github.io/SHTnsKit.jl/stable/gpu/"/><link rel="canonical" href="https://subhk.github.io/SHTnsKit.jl/stable/gpu/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">SHTnsKit.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../installation/">Installation</a></li><li><a class="tocitem" href="../quickstart/">Quick Start</a></li></ul></li><li><span class="tocitem">User Guide</span><ul><li class="is-active"><a class="tocitem" href>GPU Acceleration</a><ul class="internal"><li><a class="tocitem" href="#Quick-Start"><span>Quick Start</span></a></li><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#API-Reference"><span>API Reference</span></a></li><li><a class="tocitem" href="#Device-Management"><span>Device Management</span></a></li><li><a class="tocitem" href="#Multi-GPU-Support"><span>Multi-GPU Support</span></a></li><li><a class="tocitem" href="#Unified-Loop-Abstraction"><span>Unified Loop Abstraction</span></a></li><li><a class="tocitem" href="#Performance-Tips"><span>Performance Tips</span></a></li><li><a class="tocitem" href="#Troubleshooting"><span>Troubleshooting</span></a></li><li><a class="tocitem" href="#Example:-Complete-Workflow"><span>Example: Complete Workflow</span></a></li><li><a class="tocitem" href="#See-Also"><span>See Also</span></a></li></ul></li><li><a class="tocitem" href="../distributed/">Distributed Computing</a></li><li><a class="tocitem" href="../performance/">Performance Guide</a></li><li><a class="tocitem" href="../performance_tips/">Performance Tips</a></li><li><a class="tocitem" href="../advanced/">Advanced Usage</a></li></ul></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../api/">API Reference</a></li><li><a class="tocitem" href="../examples/">Examples Gallery</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>GPU Acceleration</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>GPU Acceleration</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/subhk/SHTnsKit.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/subhk/SHTnsKit.jl/blob/main/docs/src/gpu.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="GPU-Acceleration"><a class="docs-heading-anchor" href="#GPU-Acceleration">GPU Acceleration</a><a id="GPU-Acceleration-1"></a><a class="docs-heading-anchor-permalink" href="#GPU-Acceleration" title="Permalink"></a></h1><div style="background: linear-gradient(135deg, #059669 0%, #10b981 100%); color: white; padding: 1.5rem; border-radius: 12px; margin-bottom: 2rem;">
    <h2 style="margin: 0 0 0.5rem 0; color: white; border: none;">CUDA-Accelerated Transforms</h2>
    <p style="margin: 0; opacity: 0.9;">Significant speedup on NVIDIA GPUs with automatic CPU fallback</p>
</div><p>SHTnsKit.jl provides GPU-accelerated spherical harmonic transforms using CUDA and KernelAbstractions.jl for significant performance improvements on NVIDIA GPUs.</p><div class="admonition is-success" id="When-to-Use-GPU-b2c5b350f37adc5f"><header class="admonition-header">When to Use GPU<a class="admonition-anchor" href="#When-to-Use-GPU-b2c5b350f37adc5f" title="Permalink"></a></header><div class="admonition-body"><p>GPU acceleration is most beneficial for <strong>lmax ≥ 64</strong>. For smaller problems, CPU is often faster due to data transfer overhead.</p></div></div><hr/><h2 id="Quick-Start"><a class="docs-heading-anchor" href="#Quick-Start">Quick Start</a><a id="Quick-Start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Start" title="Permalink"></a></h2><pre><code class="language-julia hljs">using SHTnsKit, CUDA

# Check GPU availability
println(&quot;CUDA available: &quot;, CUDA.functional())
println(&quot;GPU device: &quot;, CUDA.name(CUDA.device()))

# Create configuration
lmax = 128
cfg = create_gauss_config(lmax, lmax + 2)

# Create test data
spatial = rand(cfg.nlat, cfg.nlon)

# GPU-accelerated analysis (spatial → spectral)
Alm = gpu_analysis(cfg, spatial)

# GPU-accelerated synthesis (spectral → spatial)
recovered = gpu_synthesis(cfg, Alm)

# Verify accuracy
println(&quot;Max error: &quot;, maximum(abs.(spatial - recovered)))</code></pre><hr/><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><h3 id="Requirements"><a class="docs-heading-anchor" href="#Requirements">Requirements</a><a id="Requirements-1"></a><a class="docs-heading-anchor-permalink" href="#Requirements" title="Permalink"></a></h3><ul><li>Julia 1.10+</li><li>NVIDIA GPU with CUDA support</li><li>CUDA toolkit (automatically installed via CUDA.jl)</li></ul><h3 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Pkg
Pkg.add([&quot;SHTnsKit&quot;, &quot;CUDA&quot;, &quot;GPUArrays&quot;, &quot;KernelAbstractions&quot;])

# Verify installation
using CUDA
println(&quot;CUDA version: &quot;, CUDA.version())
println(&quot;GPU: &quot;, CUDA.name(CUDA.device()))
println(&quot;Memory: &quot;, CUDA.available_memory() / 1e9, &quot; GB available&quot;)</code></pre><hr/><h2 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h2><h3 id="Core-Transforms"><a class="docs-heading-anchor" href="#Core-Transforms">Core Transforms</a><a id="Core-Transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Core-Transforms" title="Permalink"></a></h3><h4 id="gpu_analysis"><a class="docs-heading-anchor" href="#gpu_analysis"><code>gpu_analysis</code></a><a id="gpu_analysis-1"></a><a class="docs-heading-anchor-permalink" href="#gpu_analysis" title="Permalink"></a></h4><pre><code class="language-julia hljs">gpu_analysis(cfg::SHTConfig, spatial_data; device=get_device(), real_output=true)</code></pre><p>GPU-accelerated spherical harmonic analysis transform.</p><p><strong>Algorithm:</strong></p><ol><li>Transfer data to GPU</li><li>FFT along longitude (φ) using cuFFT</li><li>Legendre integration along latitude (θ) with parallel kernels</li><li>Transfer coefficients back to CPU</li></ol><p><strong>Example:</strong></p><pre><code class="language-julia hljs">cfg = create_gauss_config(64, 66)
spatial = rand(cfg.nlat, cfg.nlon)

# Basic usage
Alm = gpu_analysis(cfg, spatial)

# Complex output
Alm_complex = gpu_analysis(cfg, spatial; real_output=false)

# Force CPU fallback
Alm_cpu = gpu_analysis(cfg, spatial; device=CPU_DEVICE)</code></pre><h4 id="gpu_synthesis"><a class="docs-heading-anchor" href="#gpu_synthesis"><code>gpu_synthesis</code></a><a id="gpu_synthesis-1"></a><a class="docs-heading-anchor-permalink" href="#gpu_synthesis" title="Permalink"></a></h4><pre><code class="language-julia hljs">gpu_synthesis(cfg::SHTConfig, coeffs; device=get_device(), real_output=true)</code></pre><p>GPU-accelerated spherical harmonic synthesis transform.</p><p><strong>Algorithm:</strong></p><ol><li>Transfer coefficients to GPU</li><li>Legendre summation with parallel kernels</li><li>Inverse FFT along longitude using cuFFT</li><li>Transfer spatial field back to CPU</li></ol><p><strong>Example:</strong></p><pre><code class="language-julia hljs">cfg = create_gauss_config(64, 66)
Alm = zeros(ComplexF64, cfg.lmax+1, cfg.mmax+1)
Alm[3, 1] = 1.0  # Y_2^0 mode

# Synthesis
spatial = gpu_synthesis(cfg, Alm)

# Complex output (no Hermitian symmetry enforcement)
spatial_complex = gpu_synthesis(cfg, Alm; real_output=false)</code></pre><h3 id="Memory-Safe-Variants"><a class="docs-heading-anchor" href="#Memory-Safe-Variants">Memory-Safe Variants</a><a id="Memory-Safe-Variants-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Safe-Variants" title="Permalink"></a></h3><h4 id="gpu_analysis_safe-/-gpu_synthesis_safe"><a class="docs-heading-anchor" href="#gpu_analysis_safe-/-gpu_synthesis_safe"><code>gpu_analysis_safe</code> / <code>gpu_synthesis_safe</code></a><a id="gpu_analysis_safe-/-gpu_synthesis_safe-1"></a><a class="docs-heading-anchor-permalink" href="#gpu_analysis_safe-/-gpu_synthesis_safe" title="Permalink"></a></h4><pre><code class="language-julia hljs">gpu_analysis_safe(cfg::SHTConfig, spatial_data; device=get_device(), real_output=true)
gpu_synthesis_safe(cfg::SHTConfig, coeffs; device=get_device(), real_output=true)</code></pre><p>Memory-safe versions that automatically fall back to CPU if:</p><ul><li>Insufficient GPU memory</li><li>GPU encounters an error</li><li>CUDA is not available</li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs"># Safe for large problems - automatically falls back to CPU if needed
Alm = gpu_analysis_safe(cfg, large_spatial_data)</code></pre><h3 id="Vector-Field-Transforms"><a class="docs-heading-anchor" href="#Vector-Field-Transforms">Vector Field Transforms</a><a id="Vector-Field-Transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Vector-Field-Transforms" title="Permalink"></a></h3><h4 id="gpu_analysis_sphtor"><a class="docs-heading-anchor" href="#gpu_analysis_sphtor"><code>gpu_analysis_sphtor</code></a><a id="gpu_analysis_sphtor-1"></a><a class="docs-heading-anchor-permalink" href="#gpu_analysis_sphtor" title="Permalink"></a></h4><pre><code class="language-julia hljs">gpu_analysis_sphtor(cfg::SHTConfig, vθ, vφ; device=get_device())</code></pre><p>GPU-accelerated spheroidal-toroidal decomposition.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">cfg = create_gauss_config(32, 34)

# Create vector field components
vθ = rand(cfg.nlat, cfg.nlon)
vφ = rand(cfg.nlat, cfg.nlon)

# Decompose into spheroidal and toroidal
Slm, Tlm = gpu_analysis_sphtor(cfg, vθ, vφ)</code></pre><h4 id="gpu_synthesis_sphtor"><a class="docs-heading-anchor" href="#gpu_synthesis_sphtor"><code>gpu_synthesis_sphtor</code></a><a id="gpu_synthesis_sphtor-1"></a><a class="docs-heading-anchor-permalink" href="#gpu_synthesis_sphtor" title="Permalink"></a></h4><pre><code class="language-julia hljs">gpu_synthesis_sphtor(cfg::SHTConfig, Slm, Tlm; device=get_device(), real_output=true)</code></pre><p>GPU-accelerated vector field synthesis.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs"># Reconstruct vector field from coefficients
vθ_out, vφ_out = gpu_synthesis_sphtor(cfg, Slm, Tlm)</code></pre><h3 id="Spectral-Operators"><a class="docs-heading-anchor" href="#Spectral-Operators">Spectral Operators</a><a id="Spectral-Operators-1"></a><a class="docs-heading-anchor-permalink" href="#Spectral-Operators" title="Permalink"></a></h3><h4 id="gpu_apply_laplacian!"><a class="docs-heading-anchor" href="#gpu_apply_laplacian!"><code>gpu_apply_laplacian!</code></a><a id="gpu_apply_laplacian!-1"></a><a class="docs-heading-anchor-permalink" href="#gpu_apply_laplacian!" title="Permalink"></a></h4><pre><code class="language-julia hljs">gpu_apply_laplacian!(cfg::SHTConfig, coeffs; device=get_device())</code></pre><p>Apply the spherical Laplacian operator in spectral space: <code>Δf_lm = -l(l+1) f_lm</code></p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">Alm = rand(ComplexF64, cfg.lmax+1, cfg.mmax+1)
gpu_apply_laplacian!(cfg, Alm)  # Modifies Alm in-place</code></pre><hr/><h2 id="Device-Management"><a class="docs-heading-anchor" href="#Device-Management">Device Management</a><a id="Device-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Device-Management" title="Permalink"></a></h2><h3 id="Checking-Device-Status"><a class="docs-heading-anchor" href="#Checking-Device-Status">Checking Device Status</a><a id="Checking-Device-Status-1"></a><a class="docs-heading-anchor-permalink" href="#Checking-Device-Status" title="Permalink"></a></h3><pre><code class="language-julia hljs">using SHTnsKit, CUDA

# Get current device
device = get_device()
println(&quot;Current device: &quot;, device)  # CUDA_DEVICE or CPU_DEVICE

# Available GPUs
gpus = get_available_gpus()
for gpu in gpus
    println(&quot;GPU $(gpu.id): $(gpu.name)&quot;)
end</code></pre><h3 id="Selecting-GPU"><a class="docs-heading-anchor" href="#Selecting-GPU">Selecting GPU</a><a id="Selecting-GPU-1"></a><a class="docs-heading-anchor-permalink" href="#Selecting-GPU" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Set active GPU by ID
set_gpu_device(0)  # First GPU
set_gpu_device(1)  # Second GPU (if available)

# Force CPU execution
Alm = gpu_analysis(cfg, spatial; device=CPU_DEVICE)</code></pre><h3 id="Memory-Management"><a class="docs-heading-anchor" href="#Memory-Management">Memory Management</a><a id="Memory-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Management" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Check GPU memory
info = gpu_memory_info()
println(&quot;Free memory: &quot;, info.free / 1e9, &quot; GB&quot;)
println(&quot;Total memory: &quot;, info.total / 1e9, &quot; GB&quot;)

# Estimate memory for operation
bytes_needed = estimate_memory_usage(cfg, :analysis)
println(&quot;Memory needed: &quot;, bytes_needed / 1e6, &quot; MB&quot;)

# Check if operation will fit
if check_gpu_memory(bytes_needed)
    Alm = gpu_analysis(cfg, spatial)
else
    println(&quot;Using CPU fallback&quot;)
    Alm = analysis(cfg, spatial)
end

# Clear GPU cache
gpu_clear_cache!()</code></pre><hr/><h2 id="Multi-GPU-Support"><a class="docs-heading-anchor" href="#Multi-GPU-Support">Multi-GPU Support</a><a id="Multi-GPU-Support-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-GPU-Support" title="Permalink"></a></h2><p>For large problems, distribute work across multiple GPUs.</p><h3 id="Setup-2"><a class="docs-heading-anchor" href="#Setup-2">Setup</a><a class="docs-heading-anchor-permalink" href="#Setup-2" title="Permalink"></a></h3><pre><code class="language-julia hljs">using SHTnsKit, CUDA

# Create multi-GPU configuration
mgpu = create_multi_gpu_config(128, 130;
    strategy=:latitude,      # Split by latitude bands
    gpu_ids=[0, 1]           # Use GPUs 0 and 1
)

println(&quot;Using $(length(mgpu.gpu_devices)) GPUs&quot;)</code></pre><h3 id="Transforms"><a class="docs-heading-anchor" href="#Transforms">Transforms</a><a id="Transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Transforms" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Multi-GPU analysis
spatial = rand(130, 257)
Alm = multi_gpu_analysis(mgpu, spatial)

# Multi-GPU synthesis
recovered = multi_gpu_synthesis(mgpu, Alm)</code></pre><h3 id="Memory-Streaming"><a class="docs-heading-anchor" href="#Memory-Streaming">Memory Streaming</a><a id="Memory-Streaming-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Streaming" title="Permalink"></a></h3><p>For problems larger than GPU memory:</p><pre><code class="language-julia hljs"># Automatic chunking based on available memory
Alm = multi_gpu_analysis_streaming(mgpu, huge_spatial_data;
    max_memory_per_gpu = 4 * 1024^3  # 4 GB per GPU
)

# Estimate chunks needed
n_chunks = estimate_streaming_chunks(mgpu, size(huge_spatial_data))
println(&quot;Will use $n_chunks chunks per GPU&quot;)</code></pre><hr/><h2 id="Unified-Loop-Abstraction"><a class="docs-heading-anchor" href="#Unified-Loop-Abstraction">Unified Loop Abstraction</a><a id="Unified-Loop-Abstraction-1"></a><a class="docs-heading-anchor-permalink" href="#Unified-Loop-Abstraction" title="Permalink"></a></h2><p>The <code>@sht_loop</code> macro provides unified CPU/GPU execution:</p><pre><code class="language-julia hljs">using SHTnsKit

# Works on both CPU and GPU arrays
A = rand(100, 100)        # CPU array
B = similar(A)

@sht_loop B[I] = A[I] * 2.0 over I ∈ CartesianIndices(A)

# Same code works on GPU
using CUDA
A_gpu = CuArray(A)
B_gpu = similar(A_gpu)

@sht_loop B_gpu[I] = A_gpu[I] * 2.0 over I ∈ CartesianIndices(A_gpu)</code></pre><h3 id="Backend-Control"><a class="docs-heading-anchor" href="#Backend-Control">Backend Control</a><a id="Backend-Control-1"></a><a class="docs-heading-anchor-permalink" href="#Backend-Control" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Check current backend mode
println(loop_backend())  # &quot;auto&quot; (default)

# Force CPU SIMD (useful for debugging)
set_loop_backend(&quot;SIMD&quot;)

# Restore auto-detection
set_loop_backend(&quot;auto&quot;)</code></pre><hr/><h2 id="Performance-Tips"><a class="docs-heading-anchor" href="#Performance-Tips">Performance Tips</a><a id="Performance-Tips-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Tips" title="Permalink"></a></h2><h3 id="1.-Batch-Operations"><a class="docs-heading-anchor" href="#1.-Batch-Operations">1. Batch Operations</a><a id="1.-Batch-Operations-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Batch-Operations" title="Permalink"></a></h3><p>Minimize data transfers by batching operations:</p><pre><code class="language-julia hljs"># Inefficient: many small transfers
for field in fields
    Alm = gpu_analysis(cfg, field)
    # ... process ...
end

# Efficient: keep data on GPU
gpu_data = CuArray(stack(fields))
# Process all at once on GPU</code></pre><h3 id="2.-Use-Appropriate-Resolution"><a class="docs-heading-anchor" href="#2.-Use-Appropriate-Resolution">2. Use Appropriate Resolution</a><a id="2.-Use-Appropriate-Resolution-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Use-Appropriate-Resolution" title="Permalink"></a></h3><p>GPU overhead is significant for small problems. As a general guideline:</p><ul><li><strong>lmax &lt; 32</strong>: CPU is typically faster due to data transfer overhead</li><li><strong>lmax 32-128</strong>: GPU becomes beneficial</li><li><strong>lmax &gt; 128</strong>: GPU strongly recommended</li></ul><h3 id="3.-Preallocate-GPU-Buffers"><a class="docs-heading-anchor" href="#3.-Preallocate-GPU-Buffers">3. Preallocate GPU Buffers</a><a id="3.-Preallocate-GPU-Buffers-1"></a><a class="docs-heading-anchor-permalink" href="#3.-Preallocate-GPU-Buffers" title="Permalink"></a></h3><p>For repeated transforms:</p><pre><code class="language-julia hljs"># Create cuFFT plans once
plan = create_cufft_plan(cfg.nlat, cfg.nlon)

# Reuse buffer
buffer = CUDA.zeros(ComplexF64, cfg.nlat, cfg.nlon)
copyto!(buffer, data)

# Use preplanned FFT
gpu_fft!(plan, buffer)</code></pre><h3 id="4.-Monitor-Memory"><a class="docs-heading-anchor" href="#4.-Monitor-Memory">4. Monitor Memory</a><a id="4.-Monitor-Memory-1"></a><a class="docs-heading-anchor-permalink" href="#4.-Monitor-Memory" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Profile memory usage
CUDA.@time begin
    Alm = gpu_analysis(cfg, spatial)
end

# Check for memory leaks
for i in 1:100
    gpu_analysis(cfg, spatial)
    if i % 10 == 0
        info = gpu_memory_info()
        println(&quot;Iteration $i: $(info.free / 1e9) GB free&quot;)
    end
end</code></pre><hr/><h2 id="Troubleshooting"><a class="docs-heading-anchor" href="#Troubleshooting">Troubleshooting</a><a id="Troubleshooting-1"></a><a class="docs-heading-anchor-permalink" href="#Troubleshooting" title="Permalink"></a></h2><h3 id="Common-Issues"><a class="docs-heading-anchor" href="#Common-Issues">Common Issues</a><a id="Common-Issues-1"></a><a class="docs-heading-anchor-permalink" href="#Common-Issues" title="Permalink"></a></h3><h4 id="&quot;CUDA-not-available&quot;"><a class="docs-heading-anchor" href="#&quot;CUDA-not-available&quot;">&quot;CUDA not available&quot;</a><a id="&quot;CUDA-not-available&quot;-1"></a><a class="docs-heading-anchor-permalink" href="#&quot;CUDA-not-available&quot;" title="Permalink"></a></h4><pre><code class="language-julia hljs"># Check CUDA installation
using CUDA
println(CUDA.functional())  # Should be true
println(CUDA.version())     # Should show version

# If false, reinstall CUDA.jl
using Pkg
Pkg.rm(&quot;CUDA&quot;)
Pkg.add(&quot;CUDA&quot;)
Pkg.build(&quot;CUDA&quot;)</code></pre><h4 id="&quot;Out-of-GPU-memory&quot;"><a class="docs-heading-anchor" href="#&quot;Out-of-GPU-memory&quot;">&quot;Out of GPU memory&quot;</a><a id="&quot;Out-of-GPU-memory&quot;-1"></a><a class="docs-heading-anchor-permalink" href="#&quot;Out-of-GPU-memory&quot;" title="Permalink"></a></h4><pre><code class="language-julia hljs"># Use safe variants
Alm = gpu_analysis_safe(cfg, spatial)

# Or reduce problem size
cfg_small = create_gauss_config(64, 66)  # Instead of 256

# Or use streaming
Alm = multi_gpu_analysis_streaming(mgpu, spatial; max_memory_per_gpu=2*1024^3)</code></pre><h4 id="&quot;Numerical-differences-from-CPU&quot;"><a class="docs-heading-anchor" href="#&quot;Numerical-differences-from-CPU&quot;">&quot;Numerical differences from CPU&quot;</a><a id="&quot;Numerical-differences-from-CPU&quot;-1"></a><a class="docs-heading-anchor-permalink" href="#&quot;Numerical-differences-from-CPU&quot;" title="Permalink"></a></h4><p>GPU floating-point operations may have small differences due to:</p><ul><li>Different reduction order (non-associativity)</li><li>FMA (fused multiply-add) usage</li></ul><p>Typical differences are ~1e-14 for Float64, which is acceptable for most applications.</p><hr/><h2 id="Example:-Complete-Workflow"><a class="docs-heading-anchor" href="#Example:-Complete-Workflow">Example: Complete Workflow</a><a id="Example:-Complete-Workflow-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-Complete-Workflow" title="Permalink"></a></h2><pre><code class="language-julia hljs">using SHTnsKit, CUDA

# Setup
println(&quot;=== GPU Spherical Harmonic Transform ===&quot;)
println(&quot;GPU: &quot;, CUDA.name(CUDA.device()))
println(&quot;Memory: &quot;, CUDA.available_memory() / 1e9, &quot; GB&quot;)

# Configuration
lmax = 128
cfg = create_gauss_config(lmax, lmax + 2)
println(&quot;Grid: $(cfg.nlat) × $(cfg.nlon)&quot;)

# Create test field: Y_4^2 + Y_6^0
Alm_true = zeros(ComplexF64, cfg.lmax+1, cfg.mmax+1)
Alm_true[5, 3] = 1.0 + 0.5im  # Y_4^2
Alm_true[7, 1] = 0.8          # Y_6^0

# Synthesis on GPU
spatial = gpu_synthesis(cfg, Alm_true)
println(&quot;Spatial field: min=$(minimum(real(spatial))), max=$(maximum(real(spatial)))&quot;)

# Analysis on GPU
Alm_recovered = gpu_analysis(cfg, real.(spatial))

# Verify
error = maximum(abs.(Alm_true - Alm_recovered))
println(&quot;Roundtrip error: $error&quot;)

# Benchmark
using BenchmarkTools
println(&quot;\nBenchmarks:&quot;)
@btime gpu_analysis($cfg, $spatial)
@btime gpu_synthesis($cfg, $Alm_true)

println(&quot;Done!&quot;)</code></pre><hr/><h2 id="See-Also"><a class="docs-heading-anchor" href="#See-Also">See Also</a><a id="See-Also-1"></a><a class="docs-heading-anchor-permalink" href="#See-Also" title="Permalink"></a></h2><ul><li><a href="../performance/">Performance Guide</a> - General optimization tips</li><li><a href="../distributed/">Distributed Computing</a> - MPI parallelization</li><li><a href="../api/">API Reference</a> - Complete function documentation</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../quickstart/">« Quick Start</a><a class="docs-footer-nextpage" href="../distributed/">Distributed Computing »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 16 February 2026 19:58">Monday 16 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
