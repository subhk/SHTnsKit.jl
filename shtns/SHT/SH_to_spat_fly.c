// This file was automatically generated by 'make' from file 'fly_SH_to_spat.gen.c'.
// To modify it, please consider modifying fly_SH_to_spat.gen.c
/*
 * Copyright (c) 2010-2024 Centre National de la Recherche Scientifique.
 * written by Nathanael Schaeffer (CNRS, ISTerre, Grenoble, France).
 * 
 * nathanael.schaeffer@univ-grenoble-alpes.fr
 * 
 * This software is governed by the CeCILL license under French law and
 * abiding by the rules of distribution of free software. You can use,
 * modify and/or redistribute the software under the terms of the CeCILL
 * license as circulated by CEA, CNRS and INRIA at the following URL
 * "http://www.cecill.info".
 * 
 * The fact that you are presently reading this means that you have had
 * knowledge of the CeCILL license and that you accept its terms.
 * 
 */
 

	#ifndef SHT_AXISYM

	void GEN3(_sy1,NWAY,SUFFIX)(shtns_cfg shtns, cplx *Qlm, v2d *BrF, long int llim, const unsigned im, int it0, int it1);
  #ifndef SHT_GRAD
  #else
  #endif

	void GEN3(_sy1_hi,NWAY,SUFFIX)(shtns_cfg shtns, cplx *Qlm, v2d *BrF, long int llim, const unsigned im, int it0, int it1);
  #ifndef SHT_GRAD
  #else
  #endif
  
  #endif

	void GEN3(_sy1,NWAY,_m0l)(shtns_cfg shtns, cplx *Qlm, v2d *BrF, long int llim, int it0, int it1);
  #ifndef SHT_GRAD
  #else
  #endif


	static void GEN3(SH_to_spat_fly,NWAY,SUFFIX)(shtns_cfg shtns, cplx *Qlm, double *Vr, const long int llim) {
  #ifndef SHT_GRAD
  #else
  #endif

	unsigned imlim = 0;
	v2d* BrF = (v2d*) Vr;

  #ifndef SHT_AXISYM
	imlim = MTR;
	#ifdef SHT_VAR_LTR
		if (imlim*MRES > (unsigned) llim) imlim = ((unsigned) llim)/MRES;		// 32bit mul and div should be faster
	#endif
	if (shtns->fft_mode & FFT_OOP) {		// alloc memory for the FFT
		unsigned long nv = shtns->nspat;
		BrF = (v2d*) VMALLOC( nv * sizeof(double) );
	}
  #endif

	const int it0 = 0;
	const int it1 = NLAT_2;
	#ifndef SHT_AXISYM
	if (llim < SHT_L_RESCALE_FLY) {
	#endif
		for (int im=0; im <= imlim; im++)
		{
			for (int b=0; b<shtns->howmany; b++) {		// inner-loop is batch. For best cache-reuse
				long spec_ofs = b * shtns->spec_dist;
				long spat_ofs = b * shtns->spat_dist/2;
				GEN3(_sy1,NWAY,_l)(shtns, Qlm+spec_ofs, BrF+spat_ofs, llim, im, it0, it1);
	#ifndef SHT_GRAD
	#else
	#endif
			}
		}
  #ifndef SHT_AXISYM
	} else {

		for (int im=0; im <= imlim; im++)
		{
			for (int b=0; b<shtns->howmany; b++) {		// inner-loop is batch. For best cache-reuse
				long spec_ofs = b * shtns->spec_dist;
				long spat_ofs = b * shtns->spat_dist/2;
				GEN3(_sy1_hi,NWAY,_l)(shtns, Qlm+spec_ofs, BrF+spat_ofs, llim, im, it0, it1);
	#ifndef SHT_GRAD
	#else
	#endif
			}
		}
	}

	// padding for high m's
	if (NPHI-1 > 2*imlim) {
		const int m_inc = shtns->nlat_padded >> 1;
		for (int b=0; b<shtns->howmany; b++) {
			long spat_ofs = b * shtns->spat_dist/2;
			memset(BrF + spat_ofs + m_inc*(imlim+1), 0, sizeof(cplx)* m_inc * (NPHI-1-2*imlim));
		}
	}

    // NPHI > 1 as SHT_AXISYM is not defined.
  	if (shtns->fft_mode != FFT_NONE) {
		if ((shtns->fft_mode & FFT_PHI_CONTIG_SPLIT) == 0) {
			fftw_execute_dft(shtns->ifftc, (cplx *) BrF, (cplx *) Vr);
		} else {		// split dft
			fftw_execute_split_dft(shtns->ifftc,((double*)BrF)+1, ((double*)BrF), Vr+NPHI, Vr);
		}
		if (shtns->fft_mode & FFT_OOP) {
			VFREE(BrF);
		}
	}
  #endif

  }




  #ifndef SHT_AXISYM

	static void GEN3(SH_m_to_spat_fly,NWAY,SUFFIX)(shtns_cfg shtns, int im, cplx *Qlm, cplx *Vr, const long int llim) {
  #ifndef SHT_GRAD
  #else
  #endif

	v2d *BrF;
	#define qr(l) vall(creal(Qlm[l]))
	#define qi(l) vall(cimag(Qlm[l]))
	long int nk, k,l,m;
	double *alm, *al;
	s2d *ct, *st;

	BrF = (v2d*) Vr;

	nk = NLAT_2;
	#if _GCC_VEC_
		nk = ((unsigned)(nk+VSIZE2-1)) / VSIZE2;
	#endif
	ct = (s2d*) shtns->ct;		st = (s2d*) shtns->st;

	if (im == 0) {
		double Ql0[llim+1];

		#ifdef SHT_GRAD
		#endif

 		l=1;
		alm = shtns->glm;
		Ql0[0] = alm[0] * (double) Qlm[0];		// l=0
		do {		// for m=0, compress the complex Q,S,T to double
			double a = alm[l];
			Ql0[l] = a * (double) Qlm[l];	//	Ql[l+1] = (double) Qlm[l+1];
			++l;
		} while(l<=llim);
		alm = shtns->alm2;
		Ql0[0] *= alm[0];		// mean value kept for the end, stored in Ql0: higher accuracry
		k=0;
		do {
			l=0;	al = alm;
			rnd cost[NWAY], y0[NWAY], y1[NWAY];
			rnd re[NWAY], ro[NWAY];
			for (int j=0; j<NWAY; ++j) {
				cost[j] = vread(ct, j+k);
				y0[j] = vall(al[0]);
				re[j] = vall(0.0);		//y0[j] * vall(Ql0[0]);
			}
			for (int j=0; j<NWAY; ++j) {
				y1[j]  = vall(al[0]*al[1]) * cost[j];
			}
			for (int j=0; j<NWAY; ++j) {
				ro[j] = y1[j] * vall(Ql0[1]);
			}
			al+=2;	l+=2;
			while(l<llim) {
				for (int j=0; j<NWAY; ++j) {
					y0[j]  = vall(al[0])*(cost[j]*y1[j]) + y0[j];
				}
				for (int j=0; j<NWAY; ++j) {
					re[j] += y0[j] * vall(Ql0[l]);
				}
				for (int j=0; j<NWAY; ++j) {
					y1[j]  = vall(al[1])*(cost[j]*y0[j]) + y1[j];
				}
				for (int j=0; j<NWAY; ++j) {
					ro[j] += y1[j] * vall(Ql0[l+1]);
				}
				al+=2;	l+=2;
			}
			if (l==llim) {
				for (int j=0; j<NWAY; ++j) {
					y0[j]  = vall(al[0])*cost[j]*y1[j] + y0[j];
				}
				for (int j=0; j<NWAY; ++j) {
					re[j] += y0[j] * vall(Ql0[l]);
				}
			}
			// combine even/odd into north/south
			for (int j=0; j<NWAY; ++j) {
				rnd s = re[j] - ro[j];		re[j] = re[j] + ro[j];
				ro[j] = s;
			}
			for (int j=0; j<NWAY; ++j) {	// add mean value at the end for higher accuracy
				re[j] += vall(Ql0[0]);  // north
				ro[j] += vall(Ql0[0]);	// south
			}
		#ifndef SHTNS4MAGIC
			for (int j=0; j<NWAY; ++j) {
				S2D_CSTORE2((double*)BrF, k+j, NLAT, re[j], ro[j], vall(0), vall(0));
			}
		#else
			for (int j=0; j<NWAY; ++j) {
				if ((k+j)>=nk) break;
				S2D_CSTORE2_4MAGIC((double*)BrF, k+j, re[j], ro[j], vall(0), vall(0));
			}
		#endif
			k+=NWAY;
		} while (k < nk);

	} else {	// im > 0
		im = abs(im);			// positive im
		m = im*MRES;
		l = im*(2*(LMAX+1) -m);		// to compute position in NLM array.
		alm = shtns->alm + l+m;
		Qlm -= m;	// virtual pointer for l=0


		l = shtns->tm[im];
		l = ((unsigned) l) / VSIZE2;
		#ifndef SHTNS4MAGIC
		 	zero_poles2_vect(BrF, NLAT-l*VSIZE2, 2*l);
		#else
			#pragma omp simd
			for (k=0; k<l*4*VSIZE2; k++)	((double*)BrF)[k] = 0.0;
		#endif
		k = l;
		do {
			al = alm;
			rnd cost[NWAY], y0[NWAY], y1[NWAY];
			rnd rer[NWAY], rei[NWAY], ror[NWAY], roi[NWAY];
			for (int j=0; j<NWAY; ++j) {
				cost[j] = vread(st, k+j);
				y0[j] = vall(1.0);
			}
			l=m;
			long int ny = 0;
		  if ((int)llim <= SHT_L_RESCALE_FLY) {
			do {		// sin(theta)^m
				if (l&1) for (int j=0; j<NWAY; ++j) y0[j] *= cost[j];
				for (int j=0; j<NWAY; ++j) cost[j] *= cost[j];
			} while(l >>= 1);
		  } else {
			long int nsint = 0;
			do {		// sin(theta)^m		(use rescaling to avoid underflow)
				if (l&1) {
					for (int j=NWAY-1; j>=0; --j) y0[j] *= cost[j];
					ny += nsint;
					if (vlo(y0[NWAY-1]) < (SHT_ACCURACY+1.0/SHT_SCALE_FACTOR)) {
						ny--;
						for (int j=NWAY-1; j>=0; --j) y0[j] *= vall(SHT_SCALE_FACTOR);
					}
				}
				for (int j=NWAY-1; j>=0; --j) cost[j] *= cost[j];
				nsint += nsint;
				if (vlo(cost[NWAY-1]) < 1.0/SHT_SCALE_FACTOR) {
					nsint--;
					for (int j=NWAY-1; j>=0; --j) cost[j] *= vall(SHT_SCALE_FACTOR);
				}
			} while(l >>= 1);
		  }
			for (int j=0; j<NWAY; ++j) {
				y0[j] *= vall(al[0]);
				cost[j] = vread(ct, j+k);
				ror[j] = vall(0.0);		roi[j] = vall(0.0);
				rer[j] = vall(0.0);		rei[j] = vall(0.0);
			}
			for (int j=0; j<NWAY; ++j) {
				y1[j]  = (vall(al[1])*y0[j]) *cost[j];		//	y1[j] = vall(al[1])*cost[j]*y0[j];
			}
			l=m;		al+=2;
		  if (ny<0) {
			while (l<llim) {		// ylm treated as zero and ignored if ny < 0
				for (int j=0; j<NWAY; ++j) {
					y0[j] = (vall(al[1])*cost[j])*y1[j] + vall(al[0])*y0[j];
				}
				for (int j=0; j<NWAY; ++j) {
					y1[j] = (vall(al[3])*cost[j])*y0[j] + vall(al[2])*y1[j];
				}
				l+=2;	al+=4;
				if (fabs(vlo(y0[NWAY-1])) > SHT_ACCURACY*SHT_SCALE_FACTOR + 1.0) {		// rescale when value is significant
					for (int j=0; j<NWAY; ++j) {
						y0[j] *= vall(1.0/SHT_SCALE_FACTOR);		y1[j] *= vall(1.0/SHT_SCALE_FACTOR);
					}
					if (++ny == 0) break;
				}
			}
		  }
		  if LIKELY(ny == 0) {
			while (l<llim) {	// compute even and odd parts
				for (int j=0; j<NWAY; ++j) {	rer[j] += y0[j]  * qr(l);		rei[j] += y0[j] * qi(l);	}
				for (int j=0; j<NWAY; ++j) {
					y0[j] = vall(al[1])*(cost[j]*y1[j]) + vall(al[0])*y0[j];
				}
				for (int j=0; j<NWAY; ++j) {	ror[j] += y1[j]  * qr(l+1);		roi[j] += y1[j] * qi(l+1);	}
				for (int j=0; j<NWAY; ++j) {
					y1[j] = vall(al[3])*(cost[j]*y0[j]) + vall(al[2])*y1[j];
				}
				l+=2;	al+=4;
			}
			if (l==llim) {
				for (int j=0; j<NWAY; ++j) {	rer[j] += y0[j]  * qr(l);		rei[j] += y0[j] * qi(l);	}
			}
			// combine even/odd into north/south
			for (int j=0; j<NWAY; ++j) {
				rnd sr = rer[j] - ror[j];	rer[j] = rer[j] + ror[j];
			  	rnd si = rei[j] - roi[j];	rei[j] = rei[j] + roi[j];
				ror[j] = sr;		roi[j] = si;
			}
		  }
		#ifndef SHTNS4MAGIC
			for (int j=0; j<NWAY; ++j) {
				S2D_CSTORE2((double*)BrF, k+j, NLAT, rer[j], ror[j], rei[j], roi[j]);
			}
		#else
			for (int j=0; j<NWAY; ++j) {
				if ((k+j)>=nk) break;
				S2D_CSTORE2_4MAGIC((double*)BrF, k+j, rer[j], ror[j], rei[j], roi[j]);
			}
		#endif
			k+=NWAY;
		} while (k < nk);
	}

	#undef qr
	#undef qi
  }

  #endif
