// This file was automatically generated by 'make' from file 'fly_spat_to_SH.gen.c'.
// To modify it, please consider modifying fly_spat_to_SH.gen.c
/*
 * Copyright (c) 2010-2024 Centre National de la Recherche Scientifique.
 * written by Nathanael Schaeffer (CNRS, ISTerre, Grenoble, France).
 * 
 * nathanael.schaeffer@univ-grenoble-alpes.fr
 * 
 * This software is governed by the CeCILL license under French law and
 * abiding by the rules of distribution of free software. You can use,
 * modify and/or redistribute the software under the terms of the CeCILL
 * license as circulated by CEA, CNRS and INRIA at the following URL
 * "http://www.cecill.info".
 * 
 * The fact that you are presently reading this means that you have had
 * knowledge of the CeCILL license and that you accept its terms.
 * 
 */

//////////////////////////////////////////////////


	void GEN3(_an1,NWAY,_l)(shtns_cfg shtns, double *BrF, cplx *Qlm, const long int llim, const int imlim);
	void GEN3(_an1_hi,NWAY,_l)(shtns_cfg shtns, double *BrF, cplx *Qlm, const long int llim, const int imlim);


	static void GEN3(spat_to_SH_fly,NWAY,SUFFIX)(shtns_cfg shtns, double *Vr, cplx *Qlm, const long int llim) {


	double *BrF;		// contains the Fourier transformed data
	unsigned imlim=0;

	BrF = Vr;
  #ifndef SHT_AXISYM
	imlim = MTR;
	#ifdef SHT_VAR_LTR
		if (imlim*MRES > (unsigned) llim) imlim = ((unsigned) llim)/MRES;		// 32bit mul and div should be faster
	#endif
	if (shtns->fft_mode != FFT_NONE) {
		if (shtns->fft_mode & FFT_OOP) {		// alloc memory for out-of-place FFT
			unsigned long nv = shtns->nspat;
			BrF = (double*) VMALLOC( nv * sizeof(double) );
		}
	    if ((shtns->fft_mode & FFT_PHI_CONTIG_SPLIT) == 0) {	// regular FFT
			fftw_execute_dft(shtns->fftc,(cplx*)Vr, (cplx*)BrF);
		} else {	// split FFT
			fftw_execute_split_dft(shtns->fftc, Vr+NPHI, Vr, BrF+1, BrF);
	    }
	}
  #endif

  #ifndef SHT_AXISYM
	if (llim >= SHT_L_RESCALE_FLY) {
		for (int im=0; im<=imlim; im++) {
			for (int b=0; b<shtns->howmany; b++) {
				long spec_ofs = b * shtns->spec_dist;
				long spat_ofs = b * shtns->spat_dist;
				GEN3(_an1_hi,NWAY,_l)(shtns, BrF+spat_ofs, Qlm+spec_ofs, llim, im);
			}
		}
	} else
  #endif
	{
		for (int im=0; im<=imlim; im++) {
			for (int b=0; b<shtns->howmany; b++) {
				long spec_ofs = b * shtns->spec_dist;
				long spat_ofs = b * shtns->spat_dist;
				GEN3(_an1,NWAY,_l)(shtns, BrF+spat_ofs, Qlm+spec_ofs, llim, im);
			}
		}
	}

  #ifndef SHT_AXISYM
	if (imlim < MMAX) {		// zero out m > imlim
		long l = LiM(shtns, (imlim+1)*MRES, imlim+1);
		for (int b=0; b<shtns->howmany; b++) {
			long spec_ofs = b * shtns->spec_dist;
			memset(Qlm+l+spec_ofs, 0, (shtns->nlm - l)*sizeof(cplx));
		}
	}
  	if (shtns->fft_mode & FFT_OOP) {		// free memory
	    VFREE(BrF);
	}
  #endif

  }


  #ifndef SHT_AXISYM

	static void GEN3(spat_to_SH_m_fly,NWAY,SUFFIX)(shtns_cfg shtns, int im, cplx *Vr, cplx *Qlm, long int llim) {

	double *alm, *al;
	double *wg, *ct, *st;
	long int nk, k, l,m;
	double alm0_rescale;
	rnd qq[2*llim+4];

	double rer[NLAT_2 + NWAY*VSIZE2] SSE;
	double ror[NLAT_2 + NWAY*VSIZE2] SSE;
	double rei[NLAT_2 + NWAY*VSIZE2] SSE;
	double roi[NLAT_2 + NWAY*VSIZE2] SSE;

	nk = NLAT_2;	// copy NLAT_2 to a local variable for faster access (inner loop limit)
	#if _GCC_VEC_
	  nk = ((unsigned) nk+(VSIZE2-1))/VSIZE2;
	#endif
	wg = shtns->wg;		ct = shtns->ct;		st = shtns->st;

	for (k=nk*VSIZE2; k<(nk-1+NWAY)*VSIZE2; ++k) {
		rer[k] = 0.0;		ror[k] = 0.0;
	}

	if (im == 0) {		// im=0
		alm = shtns->alm2;
		double r0 = 0.0;
		k=0;	do {	// compute symmetric and antisymmetric parts. (do not weight here, it is cheaper to weight y0)
			#ifndef SHTNS4MAGIC
			double n = creal(Vr[k]);		double s = creal(Vr[NLAT-1-k]);
			#else
			double n = creal(Vr[2*k]);		double s = creal(Vr[2*k+1]);
			#endif
			rer[k] = n+s;			ror[k] = n-s;
			r0 += (n+s)*wg[k];
		} while(++k < nk*VSIZE2);
		{	rnd vr0 = vall(r0 * wg[-1]);
			int k=0; do {	vstor(rer, k, vread(rer, k) - vr0 );	} while(++k < nk);	// remove mean from even
		}
		alm0_rescale = alm[0] * shtns->nphi;	// alm[0] takes into account the fftw normalization, *nphi cancels it
		Qlm[0] = r0 * alm0_rescale;			// l=0 is done.
		k = 0;
		for (l=0;l<llim;++l) {
			qq[l] = vall(0.0);
		}
		do {
			al = alm;
			rnd cost[NWAY], y0[NWAY], y1[NWAY];
			rnd rerk[NWAY], rork[NWAY];		// help the compiler to cache into registers.
			for (int j=0; j<NWAY; ++j) {
				cost[j] = vread(ct, k+j);
				y0[j] = vall(alm0_rescale) * vread(wg, k+j);		// weight of Gauss quadrature appears here
				y1[j] =  (vall(al[1])*y0[j]) * cost[j];
				rerk[j] = vread(rer, k+j);		rork[j] = vread(ror, k+j);		// cache into registers.
			}
			al+=2;	l=1;
			while(l<llim) {
				for (int j=0; j<NWAY; ++j) {
					y0[j]  = vall(al[0])*(cost[j]*y1[j]) + y0[j];
				}
				for (int j=0; j<NWAY; ++j) {
					qq[l-1]   += y1[j]  * rork[j];
				}
				for (int j=0; j<NWAY; ++j) {
					y1[j]  = vall(al[1])*(cost[j]*y0[j]) + y1[j];
				}
				for (int j=0; j<NWAY; ++j) {
					qq[l]     += y0[j]  * rerk[j];
				}
				al+=2;	l+=2;
			}
			if (l==llim) {
				for (int j=0; j<NWAY; ++j) {
					qq[l-1]   += y1[j]  * rork[j];
				}
			}
			k+=NWAY;
		} while (k < nk);
		al = shtns->glm_analys;
		Qlm[0] *= al[0];
		for (l=1; l<=llim; ++l) {
			#if _GCC_VEC_
				s2d a = vdup(al[l]);
				((v2d*)Qlm)[l] = v2d_reduce(qq[l-1], vall(0)) * a;
			#else
				double a = al[l];
				Qlm[l] = qq[l-1] * a;
			#endif
		}
		#ifdef SHT_VAR_LTR
			for (l=llim+1; l<= LMAX; ++l) {
				((v2d*)Qlm)[l] = vdup(0.0);
			}
		#endif
		
	} else {		// im > 0
		im = abs(im);			// positive im

		for (k=nk*VSIZE2; k<(nk-1+NWAY)*VSIZE2; ++k) {
			rei[k] = 0.0;		roi[k] = 0.0;
		}

		m = im*MRES;
		l = shtns->tm[im] / VSIZE2;
		alm = shtns->alm2 + im*(LMAX+3) - (m*(im-1))/2;
		k = ((l*VSIZE2)>>1)*2;		// k must be even here.
		do {	// compute symmetric and antisymmetric parts.
			#ifndef SHTNS4MAGIC
			cplx n = Vr[k];			cplx s = Vr[NLAT-1-k];
			#else
			cplx n = Vr[2*k];		cplx s = Vr[2*k+1];
			#endif
			rer[k] = creal(n+s);	rei[k] = cimag(n+s);
			ror[k] = creal(n-s);	roi[k] = cimag(n-s);
		} while (++k<nk*VSIZE2);

		k=l;
		#if _GCC_VEC_
			rnd* q = qq;
		#else
			double* q = (double *) qq;	//Qlm;
		#endif
		for (l=llim+1-m; l>=0; l--) {
			q[0] = vall(0.0);		q[1] = vall(0.0);		q+=2;
		}
		alm0_rescale = alm[0] * shtns->mpos_scale_analys * (shtns->nphi*2);		// handles real-norm
		do {
		#if _GCC_VEC_
			rnd* q = qq;
		#else
			double* q = (double *) qq;	//Qlm;
		#endif
			al = alm;
			rnd cost[NWAY], y0[NWAY], y1[NWAY];
			rnd rerk[NWAY], reik[NWAY], rork[NWAY], roik[NWAY];		// help the compiler to cache into registers.
			for (int j=0; j<NWAY; ++j) {
				cost[j] = vread(st, k+j);
				y0[j] = vall(1.0);
			}
			l=m;
			long int ny = 0;	// exponent to extend double precision range.
		if ((int)llim <= SHT_L_RESCALE_FLY) {
			do {		// sin(theta)^m
				if (l&1) for (int j=0; j<NWAY; ++j) y0[j] *= cost[j];
				for (int j=0; j<NWAY; ++j) cost[j] *= cost[j];
			} while(l >>= 1);
		} else {
			long int nsint = 0;
			do {		// sin(theta)^m		(use rescaling to avoid underflow)
				if (l&1) {
					for (int j=NWAY-1; j>=0; --j) y0[j] *= cost[j];
					ny += nsint;
					if (vlo(y0[NWAY-1]) < (SHT_ACCURACY+1.0/SHT_SCALE_FACTOR)) {
						ny--;
						for (int j=NWAY-1; j>=0; --j) y0[j] *= vall(SHT_SCALE_FACTOR);
					}
				}
				for (int j=NWAY-1; j>=0; --j) cost[j] *= cost[j];
				nsint += nsint;
				if (vlo(cost[NWAY-1]) < 1.0/SHT_SCALE_FACTOR) {
					nsint--;
					for (int j=NWAY-1; j>=0; --j) cost[j] *= vall(SHT_SCALE_FACTOR);
				}
			} while(l >>= 1);
		}
			for (int j=0; j<NWAY; ++j) {
				y0[j] *= vall(alm0_rescale);
				cost[j] = vread(ct, k+j);
				y1[j]  = (vall(al[1])*cost[j]) * y0[j];
			}
			l=m;	al+=2;
		  if (ny<0) {
			while (l<llim) {		// ylm treated as zero and ignored if ny < 0
				for (int j=0; j<NWAY; ++j) {
					y0[j] = (vall(al[0])*cost[j])*y1[j] + y0[j];
				}
				for (int j=0; j<NWAY; ++j) {
					y1[j] = (vall(al[1])*cost[j])*y0[j] + y1[j];
				}
				l+=2;	al+=2;
				if (fabs(vlo(y0[NWAY-1])) > SHT_ACCURACY*SHT_SCALE_FACTOR + 1.0) {		// rescale when value is significant
					for (int j=0; j<NWAY; ++j) {
						y0[j] *= vall(1.0/SHT_SCALE_FACTOR);		y1[j] *= vall(1.0/SHT_SCALE_FACTOR);
					}
					if (++ny == 0) break;
				}
			}
		  }
		  if LIKELY(ny == 0) {
			q+=2*(l-m);
			for (int j=0; j<NWAY; ++j) {	// prefetch
				y0[j] *= vread(wg, k+j);		y1[j] *= vread(wg, k+j);		// weight appears here (must be after the previous accuracy loop).
				rerk[j] = vread( rer, k+j);		reik[j] = vread( rei, k+j);		rork[j] = vread( ror, k+j);		roik[j] = vread( roi, k+j);
			}
			while (l<llim) {	// compute even and odd parts
				for (int j=0; j<NWAY; ++j)	{	q[0] += y0[j] * rerk[j];	q[1] += y0[j] * reik[j];	}
				for (int j=0; j<NWAY; ++j) {
					y0[j] = (vall(al[0])*cost[j])*y1[j] + y0[j];
				}
				for (int j=0; j<NWAY; ++j)	{	q[2] += y1[j] * rork[j];	q[3] += y1[j] * roik[j];	}
				q+=4;
				for (int j=0; j<NWAY; ++j) {
					y1[j] = (vall(al[1])*cost[j])*y0[j] + y1[j];
				}
				l+=2;	al+=2;
			}
			if (l==llim) {
				for (int j=0; j<NWAY; ++j)	{	q[0] += y0[j] * rerk[j];	q[1] += y0[j] * reik[j];	}
			}
		  }
			k+=NWAY;
		} while (k < nk);

		double* fl = shtns->glm_analys +  im*(LMAX+3) - (m*(im-1))/2;
		#if _GCC_VEC_
			for (long l=0; l<=llim-m; ++l) {
				((v2d*)Qlm)[l]    = v2d_reduce(qq[2*l],   qq[2*l+1]) * vdup(fl[l]);
			}
		#else
			for (long l=0; l<=llim-m; ++l) {
				Qlm[l] = (qq[2*l] + I*qq[2*l+1]) * fl[l];
			}
		#endif


		#ifdef SHT_VAR_LTR
			for (long l=llim+1-m; l<=LMAX-m; ++l) {
				((v2d*)Qlm)[l] = vdup(0.0);
			}
		#endif
	}

  }

  #endif
